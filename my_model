{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/CbXuyShezz977r9MhCel"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjs6pjOoeUhU"
      },
      "source": [
        "#!/usr/bin/env python3\r\n",
        "\r\n",
        "################################################################################\r\n",
        "# Script to create and train a custom named entity model using spaCy\r\n",
        "# https://spacy.io/\r\n",
        "################################################################################\r\n",
        "\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "from pathlib import Path\r\n",
        "import random\r\n",
        "import spacy\r\n",
        "import sys\r\n",
        "from spacy.util import minibatch, compounding\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "def prepare_training_data(training_file, rows):\r\n",
        "    \"\"\"Funtion to load the training data and to clean it\r\n",
        "    Converts the data to the below format:\r\n",
        "    (\r\n",
        "        \"INPUT TEXT\",\r\n",
        "        {\"entities\": [(start_index, end_index, LABEL)]},\r\n",
        "    )\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    if not os.path.isfile(training_file):\r\n",
        "        raise FileNotFoundError(\"Training data set file '%s' not found!\" % (training_file))\r\n",
        "\r\n",
        "    df_train = pd.read_excel(training_file)\r\n",
        "\r\n",
        "    # Remove rows that have NA\r\n",
        "    if df_train.isnull().values.any():\r\n",
        "        df_train.dropna(inplace=True)\r\n",
        "        df_train.reset_index(drop=True, inplace=True)\r\n",
        "\r\n",
        "    print(\"Using first {} rows for training\".format(rows))\r\n",
        "    df_train = df_train[0:rows]\r\n",
        "\r\n",
        "    training_dataset = []\r\n",
        "    for index in range( 0, len(df_train.index) ):\r\n",
        "        entities = []\r\n",
        "        for parameter in json.loads(df_train['Parameters'][index]):\r\n",
        "            entities.append(tuple(parameter))\r\n",
        "        training_dataset.append((df_train['Question'][index], {\"entities\" : entities}))\r\n",
        "\r\n",
        "    return training_dataset\r\n",
        "\r\n",
        "\r\n",
        "def get_named_entities(training_dataset):\r\n",
        "    \"\"\"Function to get the list of named entities to be trained\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    named_entities = []\r\n",
        "\r\n",
        "    for _, annotations in training_dataset:\r\n",
        "        for ent in annotations.get(\"entities\"):\r\n",
        "            if ent[2] not in named_entities:\r\n",
        "                named_entities.append(ent[2])\r\n",
        "\r\n",
        "    named_entities.sort()\r\n",
        "\r\n",
        "    return named_entities\r\n",
        "\r\n",
        "\r\n",
        "def train_model(lang_cls, load_model, training_dataset, train_iter):\r\n",
        "    \"\"\"Function to train NER\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # load model if provided or else create a blank model for the given language class\r\n",
        "    if load_model is not None:\r\n",
        "        nlp = spacy.load(load_model)\r\n",
        "        print(\"Loading provided model '{}' ...\".format(load_model))\r\n",
        "    else:\r\n",
        "        nlp = spacy.blank(lang_cls)\r\n",
        "        print(\"Creating a blank '{}' model ...\".format(lang_cls))\r\n",
        "\r\n",
        "    # If 'ner' is not in the pipeline, add entity recognizer to model\r\n",
        "    # https://spacy.io/usage/processing-pipelines\r\n",
        "    if 'ner' not in nlp.pipe_names:\r\n",
        "        ner = nlp.create_pipe('ner')\r\n",
        "        nlp.add_pipe(ner)\r\n",
        "    else:\r\n",
        "        ner = nlp.get_pipe('ner')\r\n",
        "\r\n",
        "    # From provided dataset identify and add new labels to entity recognizer\r\n",
        "    named_entities = get_named_entities(training_dataset)\r\n",
        "    for named_entity in named_entities:\r\n",
        "        print(\"Adding custom label '{}' to entity recognizer\".format(named_entity))\r\n",
        "        ner.add_label(named_entity)\r\n",
        "\r\n",
        "    # Inititalize optimizer\r\n",
        "    print(\"Initializing optimizer ...\")\r\n",
        "    if load_model is None:\r\n",
        "        optimizer = nlp.begin_training()\r\n",
        "    else:\r\n",
        "        optimizer = nlp.entity.create_optimizer()\r\n",
        "\r\n",
        "    training_start_time = time.time()\r\n",
        "    print(\"Training NER model ...\")\r\n",
        "    print(\"Number of training iterations: {}\".format(train_iter))\r\n",
        "    \r\n",
        "    # Disable all pipes except 'ner' for training\r\n",
        "    # https://spacy.io/usage/training\r\n",
        "    disable_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\r\n",
        "    with nlp.disable_pipes(*disable_pipes):\r\n",
        "        for iter in range(train_iter):\r\n",
        "            random.shuffle(training_dataset)\r\n",
        "            losses = {}\r\n",
        "            batches = minibatch(training_dataset, size=compounding(1, 16, 1.001))\r\n",
        "            for batch in batches:\r\n",
        "                texts, annotations = zip(*batch)\r\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\r\n",
        "            print('Losses', losses)\r\n",
        "\r\n",
        "    print(\"Training done\")\r\n",
        "    \r\n",
        "    elapsed_time =  (time.time() - training_start_time)\r\n",
        "    print(\"Training time\",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\r\n",
        "    \r\n",
        "    return nlp\r\n",
        "\r\n",
        "\r\n",
        "def save_model(nlp, output_dir):\r\n",
        "    \"\"\"Function to save the model to disk\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    output_dir = Path(output_dir)\r\n",
        "    if not output_dir.exists():\r\n",
        "        output_dir.mkdir()\r\n",
        "    nlp.to_disk(output_dir)\r\n",
        "    print(\"Model saved to folder '{}'\".format(output_dir))\r\n",
        "\r\n",
        "\r\n",
        "def parse_arguments(args):\r\n",
        "    \"\"\"Function to parse input arguments\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    parser = argparse.ArgumentParser(description='Train NER')\r\n",
        "    group = parser.add_mutually_exclusive_group(required=True)\r\n",
        "    group.add_argument(\r\n",
        "        '--blank_model',\r\n",
        "        help='Create a blank model of a given language class for training'\r\n",
        "        )\r\n",
        "    group.add_argument(\r\n",
        "        '--load_model',\r\n",
        "        help='Path of model to be trained'\r\n",
        "        )\r\n",
        "    parser.add_argument(\r\n",
        "        '--train_data',\r\n",
        "        help='Path to training data',\r\n",
        "        required=True\r\n",
        "        )\r\n",
        "    parser.add_argument(\r\n",
        "        '--rows',\r\n",
        "        help='Number of rows to be considered for training',\r\n",
        "        type=int,\r\n",
        "        default=20\r\n",
        "        )\r\n",
        "    parser.add_argument(\r\n",
        "        '--train_iter',\r\n",
        "        help='Number of iterarions to train the model',\r\n",
        "        type=int,\r\n",
        "        default=10\r\n",
        "        )\r\n",
        "    parser.add_argument(\r\n",
        "        '--save_model',\r\n",
        "        help='Output directory to save the model'\r\n",
        "        )\r\n",
        "\r\n",
        "\r\n",
        "    parsed_args = parser.parse_args(args)\r\n",
        "\r\n",
        "    return parsed_args\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMhB3cNceWrF",
        "outputId": "7d7e4707-3cc9-48bc-c7f3-b254a7a162b3"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "    args = parse_arguments(['--blank_model','en','--train_data','ner_dataset_train.xlsx','--save_model','my_model','--rows','5000','--train_iter','5'])\r\n",
        "    training_dateset = prepare_training_data(args.train_data, args.rows)\r\n",
        "    nlp = train_model(args.blank_model, args.load_model, training_dateset, args.train_iter)\r\n",
        "    if args.save_model != None:\r\n",
        "        save_model(nlp, args.save_model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using first 5000 rows for training\n",
            "Creating a blank 'en' model ...\n",
            "Adding custom label 'B-art' to entity recognizer\n",
            "Adding custom label 'B-eve' to entity recognizer\n",
            "Adding custom label 'B-geo' to entity recognizer\n",
            "Adding custom label 'B-gpe' to entity recognizer\n",
            "Adding custom label 'B-nat' to entity recognizer\n",
            "Adding custom label 'B-org' to entity recognizer\n",
            "Adding custom label 'B-per' to entity recognizer\n",
            "Adding custom label 'B-tim' to entity recognizer\n",
            "Adding custom label 'I-art' to entity recognizer\n",
            "Adding custom label 'I-eve' to entity recognizer\n",
            "Adding custom label 'I-geo' to entity recognizer\n",
            "Adding custom label 'I-gpe' to entity recognizer\n",
            "Adding custom label 'I-nat' to entity recognizer\n",
            "Adding custom label 'I-org' to entity recognizer\n",
            "Adding custom label 'I-per' to entity recognizer\n",
            "Adding custom label 'I-tim' to entity recognizer\n",
            "Initializing optimizer ...\n",
            "Training NER model ...\n",
            "Number of training iterations: 5\n",
            "Losses {'ner': 13546.858165093558}\n",
            "Losses {'ner': 9696.694607206357}\n",
            "Losses {'ner': 8594.485255311993}\n",
            "Losses {'ner': 7910.992868955263}\n",
            "Losses {'ner': 7314.3504294978065}\n",
            "Training done\n",
            "Training time 00:07:20\n",
            "Model saved to folder 'my_model'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD2158VJfY63",
        "outputId": "66d92007-bc3a-44a0-b4dc-51f5180f43f0"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}